{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36-705 Intermediate Statistics.\n",
    "\n",
    "### Homework 1.\n",
    "\n",
    "### INSERT DATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Chapter 1, problem 3.\n",
    "\n",
    "Let $\\Omega$ be a sample space and let $A_1, A_2,...,$ be events. Define $B_n = \\bigcup^{\\infty}_{i=n} A_i$ and $C_n = \\bigcap^{\\infty}_{i=n} A_i$.\n",
    "\n",
    "a) Show that $B_1 \\supset B_2 \\supset ... $ and that $C_1 \\subset C_2 \\subset ... $.\n",
    "\n",
    "b) Show that $\\omega \\in \\bigcap^{\\infty}_{n=1} B_n$ if and only if $\\omega$ belongs to an infinite number of events $A_1, A_2, ...$.\n",
    "\n",
    "c) Show that $\\omega \\in \\bigcup^{\\infty}_{n=1} C_n$ if and only if $\\omega$ belongs to all event $A_1, A_2,...$ except possibly a finite number of those events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a)\n",
    "\n",
    "Listing a few terms of the sequence $B_1, B_2, B_3,...$ we have that:\n",
    "\n",
    "$$\\begin{align}\n",
    "B_1 &= \\bigcup^{\\infty}_{i=1} A_i = A_1 \\cup A_2 \\cup A_3 \\cup \\space... \\\\\n",
    "B_2 &= \\bigcup^{\\infty}_{i=2} A_i =          A_2 \\cup A_3 \\cup \\space... \\\\\n",
    "B_3 &= \\bigcup^{\\infty}_{i=3} A_i = A_3 \\cup \\space... \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Noticing that the set-difference $B_{n} - B_{n+1} = A_{n}$, we use an induction argument to prove the result.\n",
    "\n",
    "Base case $n=1$:\n",
    "\n",
    "$$B_2 - B_1 = A_1 \\implies A_1 \\cup B_1 = A_1 \\cup \\left( \\bigcup^{\\infty}_{i=2} A_i \\right) = A_1 \\cup B_1 \\implies B_2 \\subset B_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Chapter 1, problem 8.\n",
    "\n",
    "Suppose that $P(A_i) = 1$ for each $i$. Prove that:\n",
    "\n",
    "$$P\\left(\\bigcap^{\\infty}_{n=1} A_n \\right) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am struggling to prove this. In particular, it's a little peculiar how $P(A_1) = P(A_2) = ... = P(A_n) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Chapter 1, problem 13.\n",
    "\n",
    "Suppose that a fair coin is tossed repeatedly until both a head and tail have appeared at least once.\n",
    "\n",
    "a) Describe the sample space $\\Omega$.\n",
    "\n",
    "b) What is the probability that three tosses will be required?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Chapter 2, problem 1.\n",
    "\n",
    "Show that:\n",
    "\n",
    "$$P(X = x) = F(x^+) - F(x^-)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I understand that this amounts to proving that:\n",
    "\n",
    "$$P(X = x) = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Chapter 2, problem 4.\n",
    "\n",
    "Let $X$ have probabiltiy density function:\n",
    "\n",
    "$$f_X(x) = \\begin{cases}\n",
    "1/4 \\quad &0 < x < 1 \\\\\n",
    "3/8 \\quad &3 < x < 5 \\\\\n",
    "0 \\quad &\\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "a) Find the cumulative distribution function of $X$.\n",
    "\n",
    "b) Let $Y = 1/X$. Find the probability density function $f_Y(y)$ for $Y$. Hint: Consider the three cases: $\\frac{1}{5} \\leq y \\leq \\frac{1}{3}, \\frac{1}{3} \\leq y \\leq 1, y \\geq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "We are given that the random variable $X$ has the following PDF:\n",
    "\n",
    "$$ f_X(x) = \\begin{cases}\n",
    "1/4 \\quad &0 < x < 1 \\\\\n",
    "3/8 \\quad &3 < x < 5 \\\\\n",
    "0 \\quad &\\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "The CDF of $X$ is given by:\n",
    "\n",
    "$$ F_X(x) = \\int^x_{-\\infty} f_X(t) dt$$\n",
    "\n",
    "The PDF is defined piece-wise. As the range of the PDF is 0 over the domain  intervals $(-\\infty, 0], [1, 3]$ and  $[5, \\infty)$, they make no contribution to the CDF.\n",
    "\n",
    "When $x \\in (0,1)$, we have:\n",
    "\n",
    "$$F_X(x) = \\int^x_{0} \\frac{1}{4} dt = \\left[\\frac{1}{4}\\right]^x_0 = \\frac{1}{4}x$$\n",
    "\n",
    "When $x \\in (3,5)$, we have:\n",
    "\n",
    "$$\\begin{align}\n",
    "F_X(x) = \\int^1_0 \\frac{1}{4} dt + \\int^x_3 \\frac{3}{8} dt &= \\left[\\frac{1}{4}t\\right]^1_0 + \\left[\\frac{3}{8}t\\right]^x_3 = \\frac{3x-7}{8}\n",
    "\\end{align}$$\n",
    "\n",
    "So the CDF of X is:\n",
    "\n",
    "$$F_X(x) = \n",
    "\\begin{cases}\n",
    "0 \\quad & x < 0 \\\\\n",
    "\\frac{x}{4} \\quad & 0 \\leq x \\leq 1 \\\\\n",
    "\\frac{3x-7}{8} \\quad & 3 \\leq x \\leq 5 \\\\\n",
    "1 \\quad & x > 5\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Chapter 2, problem 7.\n",
    "\n",
    "Let $X$ and $Y$ be independent and suppose that each has a $\\text{Uniform}(0,1)$ distribution. Let $Z = \\text{min}\\{X, Y \\}$. Find the density $f_Z(z)$ for $Z$.\n",
    "\n",
    "Hint: It might be easier to first find $P(Z > z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For 2 indenpedent random variables $X$ and $Y$, each with $\\text{Uniform}(0,1)$ distribution, then they will joint probability density:\n",
    "\n",
    "$$f_{X,Y}(x,y) =\n",
    "\\begin{cases}\n",
    "1 \\quad & 0 < x < 1, \\quad 0 < y < 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Given a transformation of these two random variables, $Z = r(X,Y) = \\text{min}\\{X,Y\\}$, we have to find its probability density $f_Z(z)$.\n",
    "\n",
    "Define $z = r(x,y) = \\text{min}\\{x,y\\}$. Then:\n",
    "\n",
    "$$F_Z(z) = P(Z \\leq z) = P(r(x,y) \\leq z) = P(\\{(x,y): \\min \\left\\{x,y \\right\\} \\leq z \\} = \\int \\int_{A_z} f(x,y) dx dy$$\n",
    "\n",
    "To find the CDF, we need to find the set $A_z =\\{(x,y): \\min \\left\\{x,y \\right\\} \\leq z \\}$ for every $z$ in the interval $0 \\leq z \\leq 1$. We can do this by examining contour plots for various values of $z$ over the unit circle, and finding an expression for the relevant area:\n",
    "\n",
    "[INSERT IMAGE]\n",
    "\n",
    "We find that the expression for the set $A_z$, is given by $1 - (1-z)^2$, giving the CDF:\n",
    "\n",
    "$$F_Z(z) =\n",
    "\\begin{cases}\n",
    "0 \\quad &z < 0 \\\\\n",
    "1 - (1-z)^2 \\quad &0 \\leq z \\leq 1 \\\\\n",
    "1 \\quad &z > 1 \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "Checking that $F_Z(0) = 0$ and $F_Z(1) = 1$, we then have the corresponding PDF:\n",
    "\n",
    "$$f_Z(z) = \n",
    "\\begin{cases}\n",
    "2(1-z) & 0 < z < 1 \\\\\n",
    "0      & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Chapter 2, problem 20.\n",
    "\n",
    "Let $X, Y \\sim \\text{Uniform}(0, 1)$ be independent. Find the PDF for $X - Y$ and $X / Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $X, Y \\sim \\text{Uniform}(0,1)$, we need to find the PDF for $X-Y$ and $X/Y$.\n",
    "\n",
    "The joint PDF of $X$ and $Y$ is given by:\n",
    "\n",
    "$$f_{X,Y}(x,y) = \n",
    "\\begin{cases}\n",
    "1 & 0 < x < 1, 0 < y < 1 \\\\\n",
    "0 & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The CDF of an arbitrary transformation of two random variables is given by:\n",
    "\n",
    "$$F_Z(z) = P(Z \\leq z) = P(r(X,Y) \\leq z) = P(\\{(x,y): x-y \\leq z\\}) = \\int \\int_{A_z} f(x,y) dx dy$$\n",
    "\n",
    "For $X-Y$, define the transformation $Z = r(X,Y) = X-Y$ and therefore, $z = r(x,y) = x-y$. \n",
    "\n",
    "The domain of the CDF $F_Z(z)$ is given by $z_{min} = r(0,1) = 0 - 1 = -1$ and $z_{max} = r(1,0) = 1 - 0 = 1$, so we need to consider find an expression for the set  $A_z =\\{(x,y): x-y \\leq z \\}$ for every $-1 < z < 1$.\n",
    "\n",
    "We can consider a contour plot of the function z = x - y for various values of z over the unit-square:\n",
    "\n",
    "[INSERT IMAGE]\n",
    "\n",
    "We define a piece-wise expression for the area corresponding to the set $A_z$ in terms of $z$ by considering the individual intervals $z \\in [-1,0]$ and $z \\in [0, 1]$.\n",
    "\n",
    "For $z \\in [-1,0]$, we have the area $\\frac{(z+1)^2}{2}$, and for $z \\in [0,1]$, we have the area $1 - \\frac{(1-z)^2}{2}$, giving the CDF:\n",
    "\n",
    "$$F_Z(z) = \n",
    "\\begin{cases}\n",
    "0 & z < -1 \\\\\n",
    "\\frac{(z+1)^2}{2} & -1 \\leq z \\leq 0 \\\\\n",
    "1 - \\frac{(1-z)^2}{2} & 0 \\leq z \\leq 1 \\\\\n",
    "1 & z > 1 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Taking derivatives, the PDF is given by:\n",
    "\n",
    "$$f_Z(z) = \n",
    "\\begin{cases}\n",
    "z + 1 & -1 \\leq z \\leq 0 \\\\\n",
    "1 - z & 0 < z \\leq 1 \\\\\n",
    "0 & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For $X/Y$, define the transformation $Z = r(X,Y) = X/Y$, and correspondingly, $z = r(x,y) = x/y$.\n",
    "\n",
    "We have to determine the domain of the CDF $F_Z(z)$. We note that $z_{min} = r(0,y) = 0$ for $0 < y \\leq 1$, and that $z_{max} \\to \\infty$ as $y \\to 0$ for $ 0 < x \\leq 1$. \n",
    "\n",
    "And so we consider find an expression for the set $A_z$ for every $z$ in the interval $z \\in [0, \\infty)$. Below is a contour plot for the $z = x/y$ for various values of $z$ on the unit square.\n",
    "\n",
    "[INSERT IMAGE]\n",
    "\n",
    "We find piece-wise expressions for the area corresponding to the set $A_z = \\{(x,y): \\frac{x}{y} \\leq z\\}$ for the two intervals $z \\in [0, 1]$ and $z \\in [1, \\infty)$.\n",
    "\n",
    "These areas give us the following CDF:\n",
    "\n",
    "$$F_Z(z) = \n",
    "\\begin{cases}\n",
    "0 & z \\leq 0  \\\\\n",
    "\\frac{z}{2} & 0 < z \\leq 1 \\\\\n",
    "1 - \\frac{1}{2z} & z \\geq 1 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And the corrresponding PDF:\n",
    "\n",
    "$$ f_Z(z) = \n",
    "\\begin{cases}\n",
    "0 & z \\leq 0 \\\\\n",
    "\\frac{1}{2} & 0 < z \\leq 1 \\\\\n",
    "\\frac{1}{2z^2} & z > 1 \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Chapter 3, problem 8.\n",
    "\n",
    "Prove Theorem 3.17:\n",
    "\n",
    "Let $X_1, ... , X_n$ be IID and let $\\mu  = \\mathbb{E}[X_i]$, $\\sigma^2 = \\mathbb{V}[X_i]$, then:\n",
    "\n",
    "$$\\mathbb{E}[\\bar{X}_n] = \\mu, \\quad \\mathbb{V}[\\bar{X}_n] = \\frac{\\sigma^2}{n}, \\quad \\mathbb{E}[S^2_n] = \\sigma^2$$\n",
    "\n",
    "where $\\bar{X}_n = \\frac{1}{n} \\sum^n_{i=1} X_i$ is the sample mean, and $S^2_n = \\frac{1}{n-1} \\sum^n_{i=1} (X_i - \\bar{X}_n)^2$ is the sample variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sequence of I.I.D. variables $X_1, X_2,...,X_n$, each with mean $\\mu = \\mathbb{E}[X_i]$ and variance $ \\sigma^2 = \\mathbb{V}[X_i]$, and given the sample mean, $\\overline{X_n}$ and sample variance $S_n^2$ estimators:\n",
    "\n",
    "$$ \\overline{X}_n = \\frac{1}{n} \\sum^n_{i=1} X_i \\quad S^2_n = \\frac{1}{n-1} \\sum^n_{i=1} (X_i - \\overline{X}_n)^2$$\n",
    "\n",
    "We have to prove the following properties of sampling distribution:\n",
    "\n",
    "$$\\mathbb{E}[\\overline{X}_n] = \\mu \\quad \\mathbb{V}(\\overline{X}_n) = \\frac{\\sigma^2}{n} \\quad \\mathbb{E}[S^2_n] = \\sigma^2$$\n",
    "\n",
    "For the mean of the sample mean estimator, we use the linearity of the expectations operator to yield:\n",
    "\n",
    "$$\\mathbb{E}[\\overline{X}_n] = \\mathbb{E} \\left [\\frac{1}{n} \\sum^n_{i=1} X_i \\right] = \\frac{1}{n} \\sum^n_{i=1} \\mathbb{E}[X_i] = \\frac{n \\mu}{n} = \\mu $$\n",
    "\n",
    "And for the variance of the sampling mean estimator:\n",
    "\n",
    "$$\\mathbb{V}(\\overline{X}_n) = \\mathbb{V} \\left [ \\frac{1}{n} \\sum^n_{i=1} X_i \\right] = \\sum^n_{i=1} (\\frac{1}{n})^2 \\mathbb{V}(X_i) = \\frac{1}{n^2} \\sum^n_{i=1} \\mathbb{V}(X_i) = \\frac{n \\sigma^2}{n^2} = \\frac{\\sigma}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mean of the sample variance estimator:\n",
    "\n",
    "From the above results:\n",
    "\n",
    "$$\\mathbb{E}[X_i]^2  = \\mu^2 \\quad \\mathbb{E}[\\overline{X}_n] = \\mu^2  $$\n",
    "\n",
    "And using the formula for the 2nd moment in terms of variance and expectation squared $\\mathbb{E}[Y^2] = \\mathbb{V}[Y] + \\mathbb{E}[Y]^2$, we have:\n",
    "\n",
    "$$\\mathbb{E}[{X_i}^2] = \\sigma^2 + \\mu^2 \\quad \\mathbb{E}[\\overline{X_n}^2] = \\frac{\\sigma^2}{n} + \\mu^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\mathbb{E}[S^2_n] &= \\frac{1}{n-1}\\mathbb{E}\\left[\\sum^n_{i=1}(X_i - \\overline{X}_n)^2 \\right ] \\\\\n",
    "&= \\frac{1}{n-1}\\mathbb{E} \\left[ \\sum^n_{i=1} (X^2_i - 2X_i\\overline{X}_n + \\overline{X}^2) \\right ] \\\\\n",
    "&= \\frac{1}{n-1} \\left \\{ \\sum^n_{i=1} \\mathbb{E}[X^2_i] - 2\\mathbb{E} \\left[ \\sum^n_{i=1} X_i \\overline{X}_n \\right] + \\sum^n_{i=1}\\mathbb{E}[\\overline{X}^2_n] \\right \\} \\\\\n",
    "&= \\frac{1}{n-1} \\left \\{ \\sum^n_{i=1} \\mathbb{E}[X^2_i] - 2\\mathbb{E} [n\\overline{X}^2_n] + \\sum^n_{i=1}\\mathbb{E}[\\overline{X}^2_n] \\right \\} \\\\\n",
    "&= \\frac{1}{n-1} \\left \\{ n(\\sigma^2 + \\mu^2) -2n(\\frac{\\sigma^2}{n} + \\mu^2) + n(\\frac{\\sigma^2}{n} + \\mu^2) \\right \\} \\\\\n",
    "&= \\frac{1}{n-1} \\left \\{ n\\sigma^2 + n\\mu^2 - 2\\sigma^2 - 2n\\mu^2 + \\sigma^2 + n\\mu^2 \\right\\} \\\\\n",
    "&= \\frac{(n-1)\\sigma^2}{n-1} \\\\\n",
    "&= \\sigma^2 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Where in the third equality we have used the above results and the fact that $\\sum^n_{i=1} X_i = n \\overline{X}_n$, completing our Proof of Theorem 3.17.\n",
    "\n",
    "The statement that the mean of the sample variance estimator, $\\mathbb{E}[S^2_n]$ is equal to the variance $\\sigma^2$ of the IID random variables can be interpreted as the sample variance estimator being an unbiased estimator of the population variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Chapter 3, problem 22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X \\sim \\text{Uniform}(0,1)$. Let $0< a < b < 1$. Let\n",
    "\n",
    "$$Y = \n",
    "\\begin{cases}\n",
    "1 \\quad &0 < x < b \\\\\n",
    "0 \\quad &\\text{otherwise}\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "and let\n",
    "\n",
    "$$Z = \n",
    "\\begin{cases}\n",
    "1 \\quad &a < x < 1 \\\\\n",
    "0 \\quad &\\text{otherwise}\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "a) Are $Y$ and $Z$ independent?\n",
    "\n",
    "b) Find $\\mathbb{E}[Y|Z]$. Hint: What values $z$ can $Z$ take? Now find $\\mathbb{E}[Y | Z = z]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9a)\n",
    "\n",
    "We compute the joint PMF $f_{Y, Z}(y,z)$ by partitioning the interval $[0,1]$ into the intervals $(0, a)$, $(a,b)$, $(a, 1)$ and $(b, 1)$. \n",
    "\n",
    "$$\\begin{array} {|r|r|}\\hline  & Z = 0 &  Z = 1 & f_{Y}(y) \\\\ \\hline Y = 0 & 0 & (1-b) & (1-b) \\\\ \\hline Y = 1 & a & (b-a) & b \\\\ \\hline f_{Z}(z) & a & (1-a) & 1 \\\\ \\hline  \\end{array}$$\n",
    "\n",
    "As $f_{Y, Z}(y, z) \\neq f_{Z}(z)f_{Y}(y)$, $Y$ and $Z$ are not independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9b)\n",
    "\n",
    "We can now compute the conditional PMF $f_{Y|Z}(y|z)$:\n",
    "\n",
    "$$f_{Y | Z}(y|z) = \\frac{f_{Y, Z}(y, z)}{f_Z(z)}$$\n",
    "\n",
    "Which can be summarised as follows:\n",
    "\n",
    "$$\\begin{array} {|r|r|}\\hline  & Z = 0 & Z = 1 \\\\ \\hline Y = 0 & 0 & \\frac{1-b}{1-a} \\\\ \\hline Y = 1 & 1 & \\frac{b-a}{1-a} \\\\ \\hline  \\end{array}$$\n",
    "\n",
    "Computing conditional expectations, we have that:\n",
    "\n",
    "$$\\mathbb{E}[Y | Z = 0] = 0 \\cdot P(Y = 0 | Z = 0) + 1 \\cdot P(Y = 1 | Z = 0) = 1$$\n",
    "\n",
    "And that:\n",
    "\n",
    "$$\\mathbb{E}[Y | Z = 1] = 0 \\cdot P(Y = 0 | Z = 1) + 1 \\cdot P(Y = 1 | Z = 1) = \\frac{b-a}{1-a}$$\n",
    "\n",
    "Hence we have that $\\mathbb{E}[Y | Z] = \\left(\\frac{b-a}{1-a} \\right)^{1 - Z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Chapter 3, problem 23.\n",
    "\n",
    "Find the moment generating function for the Poisson, Normal, and Gamma distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "$ X \\sim \\text{Poisson}(\\lambda)$, with mean and variance, $\\mathbf{E}[X] = \\mathbf{V}[X] = \\lambda$, with PDF:\n",
    "\n",
    "$$ f_X(x) = e^{- \\lambda}\\frac{\\lambda^x}{x!} \\quad x \\geq 0$$\n",
    "\n",
    "The moment generating function (MGF) is given by:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\psi_X(t) = \\mathbf{E}[e^{tX}] &= \\sum^{\\infty}_{x=0} e^{tx} e^{- \\lambda} \\frac{\\lambda^x}{x!} \\\\\n",
    "          &= e^{- \\lambda} \\sum^{\\infty}_{x=0} e^{tx} \\frac{\\lambda^x}{x!} \\\\\n",
    "          &= e^{- \\lambda} \\sum^{\\infty}_{x=0} \\frac{({\\lambda e^t})^x}{x!} \\\\\n",
    "          &= e^{- \\lambda} e^{\\lambda e^t} \\\\\n",
    "          &= e^{\\lambda(e^t - 1)} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "The key step is noting that the infinite series expansion of $e^{\\lambda}$ is the following:\n",
    "\n",
    "$$e^{\\lambda} = \\sum^{\\infty}_{x=0} \\frac{\\lambda^x}{x!}$$\n",
    "\n",
    "meaning that $e^{\\lambda e^t}$ will have infinite series the expansion:\n",
    "\n",
    "$$e^{\\lambda e^t}= \\sum^{\\infty}_{x=0} \\frac{({\\lambda e^t})^x}{x!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a univariate, continuous random variable $X$ such that $X \\sim N(\\mu, \\sigma^2)$ with mean $\\mu$ and variance $\\sigma^2$, which has PDF:\n",
    "\n",
    "$$ f_X(x) =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp} \\left \\{-\\frac{1}{2 \\sigma^2}(x- \\mu)^2 \\right \\} \\quad x \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MGF is given by:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[e^{tX}] &= \\int^{\\infty}_{- \\infty}  \\frac{1}{\\sigma \\sqrt{2\\pi}} \\text{exp} \\left \\{-\\frac{1}{2 \\sigma^2} (x- \\mu)^2 \\right \\} \\text{exp} (tx) dx \\\\\n",
    "&= \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int^{\\infty}_{- \\infty} \\text{exp} \\left \\{ -\\frac{1}{2 \\sigma^2}(x- \\mu)^2 + tx \\right \\} dx \\\\\n",
    "&= \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int^{\\infty}_{- \\infty} \\text{exp} \\left \\{ \\frac{-x^2 + x(2\\mu + 2t\\sigma^2) - \\mu^2}{2 \\sigma^2} \\right \\} dx \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will complete the square in the numerator of the RHS, noting that a general quadratic can be expressed:\n",
    "\n",
    "$$ ax^2 + bx + c = a \\left ( x + \\frac{b}{2a} \\right)^2 + \\left(c - \\frac{b^2}{4a} \\right)$$\n",
    "\n",
    "Setting $a = -1$, $b = 2 \\mu + 2t \\sigma^2$, and $c = -\\mu^2$, and resuming from above, we have:\n",
    "\n",
    "$$\\begin{align} \n",
    "\\mathbb{E}[e^{tX}] &= \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int^{\\infty}_{- \\infty} \\text{exp} \\left \\{ \\frac{-[x-(\\mu + t \\sigma^2)]^2 + (2t \\mu \\sigma^2 + t^2 \\sigma^4)}{2 \\sigma^2} \\right \\} dx \\\\\n",
    "&= \\text{exp} \\left \\{\\frac{2 t \\mu + t^2 \\sigma^2}{2} \\right \\} \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int^{\\infty}_{- \\infty} \\text{exp} \\left \\{ \\frac{-[x-(\\mu + t \\sigma^2)]^2}{2 \\sigma^2} \\right \\} dx \\\\\n",
    "&= \\text{exp} \\left \\{ t \\mu + \\frac{t^2 \\sigma^2}{2} \\right \\}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last equality holds due to the observation in the penultimate equality that the term to the right of the exponential function has the same functional form as probability density for a Normally distributed random variable $Y \\sim N(\\mu + t \\sigma^2, \\sigma^2)$, and also that the integral must of a density must be 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $X \\sim \\text{Gamma}(\\alpha, \\beta)$ with parameters $a$ and $b$, we have the following PDF for $x > 0$:\n",
    "\n",
    "$$f_X(x) = \\frac{1}{\\beta^{a} \\Gamma({a})} x^{a-1} e^{\\frac{-x}{\\beta}}$$\n",
    "\n",
    "where $a > 0$ and $\\Gamma(a) = \\int^{\\infty}_0 y^{a-1} e^{\\frac{-x}{\\beta}}$.\n",
    "\n",
    "The MGF $\\mathbb{E}[e^{tX}]$ is:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[e^{tX}] = \\psi_X(t) &= \\int^{\\infty}_0 e^{tx} f_X(x) dx \\\\\n",
    "&= \\int^{\\infty}_0 \\frac{1}{\\beta^{\\alpha} \\Gamma(a)} x^{\\alpha-1} e^{tx - \\frac{x}{\\beta}} dx \\\\\n",
    "&= \\frac{1}{\\beta^{\\alpha} \\Gamma(a)} \\int^{\\infty}_0 x^{\\alpha-1} e^{-x \\left( t - \\frac{1}{\\beta} \\right)} dx\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Integrating by substitution, and setting $y = x\\left( \\frac{1}{\\beta} - t \\right) \\implies x = \\frac{\\beta y }{1 - \\beta t}$, and with $\\frac{dy}{dx} = \\left(\\frac{1}{\\beta} - t \\right)$, we have that:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[e^{tX}] = \\psi_X(t)  &= \\frac{1}{\\beta^{\\alpha} \\Gamma(a)} \\int^{\\infty}_0 \\left(\\frac{\\beta y }{1 - \\beta t} \\right)^{\\alpha-1} e^{-y} \\left(\\frac{1}{\\beta} - t \\right)^{-1} dy \\\\\n",
    "&= \\frac{1}{\\beta^{\\alpha} \\Gamma(a)} \\int^{\\infty}_0 \\frac{y^{\\alpha - 1}}{\\left (1 - \\beta t \\right)^{\\alpha}} e^{-y} dy \\\\\n",
    "&= \\frac{1}{\\beta^{\\alpha} \\Gamma(a)\\left (1 - \\beta t \\right)^{\\alpha}} \\underbrace{\\int^{\\infty}_0 y^{\\alpha - 1} e^{-y} dy}_{\\Gamma(\\alpha)}\\\\\n",
    "&= \\frac{1}{\\beta^{\\alpha} \\left( \\frac{1}{\\beta} - t \\right)^{\\alpha}}\n",
    "\\end{align}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
