{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36-705 Intermediate Statistics.\n",
    "\n",
    "### Homework 2.\n",
    "\n",
    "### INSERT DATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Let $X$ have mean 0. We say that $X$ is sub-Gaussian if there exists $\\sigma > 0$ such that:\n",
    "\n",
    "$$\\quad \\log(\\mathbb{E}[e^{tX}]) \\leq \\frac{t^2 \\sigma^2}{2} \\quad \\forall t$$\n",
    "\n",
    "i) Show that $X$ is sub-Gaussian if and only if $-X$ is sub-Gaussian.\n",
    "\n",
    "ii) Let $X$ have mean $\\mu$. Suppose that $X - \\mu$ is sub-Gaussian. Show that:\n",
    "\n",
    "$$\\mathbb{P}(|X - \\mu | \\geq t) \\leq 2e^{-t^2/(2\\sigma^2)}$$\n",
    "\n",
    "**Remark**: When people say \"$X$ is sub-Gaussian\", they often mean that \"$X- \\mu$ is sub-Gaussian.\"\n",
    "\n",
    "iii) Suppose that $X$ is sub-Gaussian. Show that for any $p > 0$,\n",
    "\n",
    "$$\\mathbb{E}[|X|^p] \\leq p 2^{p/2} \\sigma^p \\Gamma(p/2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) i)\n",
    "\n",
    "Assuming that $X$ is sub-Gaussian, we consider the following expression on the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ii) \n",
    "\n",
    "We start by considering the one-tailed behaviour of the random variable $X$ from its mean $\\mathbb{E}[X] = \\mu$, that is $P(X - \\mu > t)$.\n",
    "\n",
    "As we have information on the mean of the random variable $X$, Markov's inequality yields the following for all $t > 0$:\n",
    "\n",
    "$$P(X - \\mu \\geq t) = P(e^{(X- \\mu)} \\geq e^{t}) \\leq \\frac{\\mathbb{E}[e^{(X-\\mu)}]}{e^{t}}$$\n",
    "\n",
    "We can now introduce a variational parameter $s > 0$, and we have that the following inequality holds for all $s \\geq 0$:\n",
    "\n",
    "$$P(X - \\mu \\geq t) = P(e^{s(X- \\mu)} \\geq e^{st}) \\leq \\frac{\\mathbb{E}[e^{s(X-\\mu)}]}{e^{st}}$$\n",
    "\n",
    "As $s$ is a variational parameter, we can select it to minimise the RHS and get a tighter upper bound on the probability, to get the 1st inequality below, which is known as Chernoff's method.\n",
    "\n",
    "$$P(X - \\mu \\geq t) \\leq \\underset{s \\geq 0}{\\text{inf}} \\space \\frac{\\mathbb{E}[e^{s(X-\\mu)}]}{e^{st}}$$\n",
    "\n",
    "As we also know that $X - \\mu$ is sub-Gaussian by assumption, we know that for all $t$, there exists a $\\sigma > 0$ such that $\\mathbb{E}[e^{tX}] \\leq \\text{exp}(\\frac{t^2 \\sigma^2}{2})$, and therefore we have that:\n",
    "\n",
    "$$\\frac{\\mathbb{E}[e^{s(X-\\mu)}]}{e^{st}} \\leq e^{(s^2 \\sigma^2)/2} e^{-st}$$\n",
    "\n",
    "We now minimise the RHS with respect to the variational parameter $s$ by differentiating, setting to 0 and solving for $s$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{d}{ds} \\exp \\left(\\frac{s^2 \\sigma^2}{2} - st \\right) =\n",
    "\\exp \\left( \\frac{s^2 \\sigma^2}{2} - st \\right) (s \\sigma^2 - t) &= 0 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "For fixed $t$, the exponentiated term in the middle equality can only equal 0 in the limit, that is when $s \\rightarrow - \\infty$, and because $s \\geq 0$, we can discard this term by dividing it out. Hence we have that bound is minimised, and therefore tight, when we set the variational parameter to be:\n",
    "\n",
    "$$s = \\frac{t}{\\sigma^2}$$\n",
    "\n",
    "Evaluating the bound, we have that:\n",
    "\n",
    "$$\\exp \\left( \\frac{s^2 \\sigma^2}{2} - st \\right) = \\exp \\left( \\frac{t^2 \\sigma^2}{2 \\sigma^4} - \\frac{t^2}{\\sigma^2} \\right) = \\exp \\left(\\frac{-t^2}{2 \\sigma^2} \\right)$$\n",
    "\n",
    "And hence we have the following one-sided tail bound:\n",
    "\n",
    "$$P(X - \\mu \\geq t) \\leq \\exp \\left(\\frac{-t^2}{2 \\sigma^2} \\right)$$\n",
    "\n",
    "We are now interested in bounding the upper and lower tail probabilities:\n",
    "\n",
    "$$P(X - \\mu \\geq t) + P(X - \\mu \\leq -t) = P(X - \\mu \\geq t) + P(-(X - \\mu) \\geq t) = P(|X - \\mu | \\geq t)$$\n",
    "\n",
    "Now because $X - \\mu$ is sub-Gaussian, we know from part (i) that $-(X - \\mu)$ is also sub-Gaussian. Hence we can use similar calculations to show that:\n",
    "\n",
    "$$\\begin{align}\n",
    "P(-(X - \\mu ) \\geq t) &\\leq \\frac{\\mathbb{E}[e^{-s(X - \\mu)}]}{e^{s t}} \\\\\n",
    "& \\leq \\exp \\left( \\frac{s^2 \\sigma^2}{2} \\right) \\exp(-st) \\\\\n",
    "& \\leq \\exp \\left( \\frac{- t^2}{2 \\sigma^2} \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Hence we have that:\n",
    "\n",
    "$$P(|X - \\mu | \\geq t) \\leq 2e^{-t^2/(2 \\sigma^2)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) iii).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Let $X_1, X_2,..., X_n$ be IID with mean $\\mu$, $\\text{Var}[X_i] = \\sigma^2$ and $|X_i| \\leq c$. Bernstein's inequality says that:\n",
    "\n",
    "$$\\mathbb{P}(| \\bar{X}_n - \\mu | > t) \\leq 2 \\exp \\left\\{-\\frac{nt^2}{2\\sigma^2 + 2ct/3}\\right\\}$$\n",
    "\n",
    "Suppose that $\\sigma^2 = O(1/n)$. Use Bernstein's inequality to show that $\\bar{X}_n - \\mu = O_P(1/n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Prove or disprove the following:\n",
    "\n",
    "i) If $X_n = O_P(a_n)$ and $Y_n = O(b_n)$ then $X_n + Y_n = O_P(a_n b_n)$.\n",
    "\n",
    "ii) If $X_n = o_P(a_n)$ and $Y_n = o_P(b_n)$ then $X_n + Y_n = o_P(\\text{min}\\{a_n b_n \\})$.\n",
    "\n",
    "iii) If $X_n = o_P(a_n)$ and $Y_n = O_P(b_n)$ then $X_n/Y_n = o_P(a_n/b_n)$.\n",
    "\n",
    "iv) If $X_n = O_P(a_n)$ and $Y_n = O_P(b_n)$ then $X_n Y_n = o_p(a_n b_n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Let $U \\sim \\text{Uniform}(0,1)$. Let $Y = F^{-1}(U)$ where $F$ is a continuous CDF on the real line. Show that the distribution of $Y$ is $F$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
